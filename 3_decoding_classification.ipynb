{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Brain Decoding: Classification\n",
    "\n",
    "This notebook provides a simple brain decoding analysis tutorial: **classification of stimulus image categories from fMRI signals**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For Kamitani lab members:*\n",
    "\n",
    "Please skip the following cell if you run this notebook in Kamitani lab servers.\n",
    "This notebook works on the default Python environment of our servers without additional package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install hdf5storage\n",
    "!pip install git+https://github.com/KamitaniLab/bdpy.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires the following Python packages.\n",
    "Please install them via pip (or conda).\n",
    "\n",
    "- bdpy\n",
    "- numpy\n",
    "- sklearn\n",
    "- matplotlib\n",
    "- hdf5storage\n",
    "- tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://ndownloader.figshare.com/files/28215453\\?private_link=3bd9a1c29f19649c8c0d -o data/sub-04_ImageNet12Cat_volume_native_preproc.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import bdpy\n",
    "import bdpy.ml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of stimulus image categories\n",
    "\n",
    "In this notebook, we will classify categories of images from fMRI signals collected from a human subject viewing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimuli and experiment design\n",
    "\n",
    "In the experiment, brain activity was collected with fMRI from a subject viewing static images.\n",
    "The images were selected from ImageNet.\n",
    "One of 240 images (20 images/category * 12 categories) was presented for 8 seconds in each trial (flashed at every 500 msec).\n",
    "Each image presentation trial was initiated by red-flashing of the fixation point.\n",
    "Each run was composed of 13 image presentation trials including one-back repetition trials.\n",
    "In one-back repetition trials, the same image presented in the previous trial was shown again.\n",
    "The subject was required to press a key when the same image was presented again.\n",
    "This \"one-back repetition task\" was introduced to keep the subject's attention to the visual images.\n",
    "\n",
    "12 categories:\n",
    "\n",
    "1. animal\n",
    "2. body part\n",
    "3. cloth\n",
    "4. dish\n",
    "5. furniture\n",
    "6. human\n",
    "7. indoor\n",
    "8. natural food\n",
    "9. outdoor\n",
    "10. plant\n",
    "11. tool\n",
    "12. vehicle\n",
    "\n",
    "### MRI data acquisition\n",
    "\n",
    "- Voxel size: 2 mm isotropic\n",
    "- FOV: 192x192 mm\n",
    "- 76 slices\n",
    "- TR: 2 sec\n",
    "- Multi-band EPI\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "The following preprocessing was applied after the typical preprocessing of fMRI signals with SPM (slice timing correction, motion correction, anatomical-functional coregistration).\n",
    "\n",
    "- Temporal shifting of samples\n",
    "- Regressing-out motion parameters, mean subtraction, and linear detrending\n",
    "- Outlier reduction\n",
    "- Temporal averaging within blocks (trials)\n",
    "- Removal of rest and repetition blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata = bdpy.BData('data/sub-04_ImageNet12Cat_volume_native_preproc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hands-on, we use fMRI responses in the lateral occipital complex (LOC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data_loc = bdata.select('ROI_LOC')\n",
    "print('fMRI data (samples x voxels): {}'.format(fmri_data_loc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus labels\n",
    "stimulus_labels = bdata.get_label('stimulus_name')\n",
    "stimulus_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = bdata.get_label('category_name')\n",
    "category_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this analysis is to predict the category labels from fMRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run numbers\n",
    "runs = bdata.select('Run')\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the model performance with cross-validation.\n",
    "Specifically, we will conduct *run-wise corss-validation* or *leave-one-run-out cross-validation*, in which samples from each run consisute each fold of K-folds cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything you need for the decoding analysis is ready. The fMRI data is saved as an array of sample-by-feature (voxels), so you can run the decoding with typical machine learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvindex = bdpy.ml.cvindex_groupwise(runs)\n",
    "\n",
    "prediction_accuracy_cv = []\n",
    "\n",
    "for ind_train, ind_test in cvindex:\n",
    "    x_train = fmri_data_loc[ind_train, :]\n",
    "    y_train = np.array(category_labels)[ind_train]\n",
    "    x_test = fmri_data_loc[ind_test, :]\n",
    "    y_test = np.array(category_labels)[ind_test]\n",
    "    \n",
    "    # Normalization\n",
    "    norm_mean = np.mean(x_train, axis=0)\n",
    "    norm_scale = np.std(x_train, axis=0, ddof=1)\n",
    "    \n",
    "    x_train = (x_train - norm_mean) / norm_scale\n",
    "    x_test = (x_test - norm_mean) / norm_scale\n",
    "\n",
    "    # Model training\n",
    "    model = sklearn.svm.LinearSVC()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    prediction_accuracy_cv.append(acc)\n",
    "    \n",
    "prediction_accuracy = np.mean(prediction_accuracy_cv)\n",
    "print('Prediciton accuracy: {}'.format(prediction_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy is acutally modest but higher than the chance level ($1 / 12 = 0.08$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Try classification with fMRI data from early visual areas (V1 + V2 + V3), LOC, FFA, and PPA. Then, plot the prediction accuracies as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ['Early', 'LOC', 'FFA', 'PPA']\n",
    "rois_select = {\n",
    "    'Early': 'ROI_V1 + ROI_V2 + ROI_V3',\n",
    "    'LOC':   'ROI_LOC',\n",
    "    'FFA':   'ROI_FFA',\n",
    "    'PPA':   'ROI_PPA',\n",
    "}\n",
    "\n",
    "prediction_accuracies = []\n",
    "\n",
    "# Your code comes here\n",
    "\n",
    "# Plotting\n",
    "xticks = list(range(len(rois)))\n",
    "\n",
    "plt.bar(xticks, prediction_accuracies)\n",
    "\n",
    "plt.xlim([-1, len(rois)])\n",
    "plt.xticks(xticks)\n",
    "plt.gca().set_xticklabels(rois)\n",
    "\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Chance level\n",
    "plt.plot([-1, len(rois)], [1 / 12, 1 / 12], color='k', linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Try another classification methods such as logistic regression. Use fMRI signals in \"LOC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Typically, decoding or machine learning-based analysis of fMRI data is suffered from overfitting due to high dimensionality of the features (voxels). Think of a method to solve the overfitting on fMRI, implement it, and see whether it works or not. Use fMRI signals in \"LOC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Pereira et al. (2009) Machine learning classifiers and fMRI: A tutorial overview. NeuroImage. [doi:10.1016/j.neuroimage.2008.11.007](http://dx.doi.org/10.1016/j.neuroimage.2008.11.007)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
